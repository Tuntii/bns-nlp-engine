{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantik Arama (Semantic Search)",
    "",
    "Bu notebook, bns-nlp-engine'in farklı vektör veritabanları ile semantik arama özelliklerini gösterir."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import asyncio",
    "import os",
    "import time",
    "import numpy as np",
    "from bnsnlp.search import FAISSSearch, QdrantSearch, PineconeSearch",
    "from bnsnlp.embed import HuggingFaceEmbedder, OpenAIEmbedder",
    "from bnsnlp.preprocess import TurkishPreprocessor"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. FAISS - Yerel Vektör Arama",
    "",
    "FAISS, Facebook'un geliştirdiği yerel vektör arama kütüphanesidir. API key gerektirmez."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Embedder oluştur",
    "embed der = HuggingFaceEmbedder({",
    "    'model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',",
    "    'use_gpu': False",
    "})",
    "",
    "# Test embedding boyutunu al",
    "test_result = await embedder.embed(\"test\")",
    "dimension = test_result.dimensions",
    "",
    "print(f\"Embedding boyutu: {dimension}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# FAISS search oluştur",
    "faiss_search = FAISSSearch({",
    "    'dimension': dimension,",
    "    'index_path': 'faiss_demo.index'",
    "})",
    "",
    "print(\"✓ FAISS search hazır\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Örnek dökümanlar",
    "documents = [",
    "    \"Python güçlü bir programlama dilidir\",",
    "    \"Makine öğrenmesi yapay zeka alt dalıdır\",",
    "    \"Doğal dil işleme metinleri analiz eder\",",
    "    \"Veri bilimi veriden içgörü çıkarır\",",
    "    \"Derin öğrenme sinir ağları kullanır\",",
    "    \"JavaScript web geliştirme için kullanılır\",",
    "    \"SQL veritabanı sorgulama dilidir\",",
    "    \"Docker konteyner teknolojisidir\",",
    "    \"Kubernetes orkestrasyon platformudur\",",
    "    \"React kullanıcı arayüzü kütüphanesidir\"",
    "]",
    "",
    "print(f\"{len(documents)} döküman hazırlandı\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Embedding'leri oluştur",
    "print(\"Embedding'ler oluşturuluyor...\")",
    "start = time.time()",
    "embed_result = await embedder.embed(documents)",
    "elapsed = time.time() - start",
    "",
    "print(f\"✓ {len(embed_result.embeddings)} embedding oluşturuldu ({elapsed:.2f}s)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# İndeksle",
    "ids = [str(i) for i in range(len(documents))]",
    "metadata = [{'category': 'tech', 'index': i, 'length': len(doc)} for i, doc in enumerate(documents)]",
    "",
    "await faiss_search.index(documents, embed_result.embeddings, ids, metadata)",
    "",
    "print(f\"✓ {len(documents)} döküman indekslendi\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basit Arama"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Arama yap",
    "query = \"yapay zeka ve makine öğrenmesi\"",
    "",
    "# Query embedding",
    "query_result = await embedder.embed(query)",
    "query_embedding = query_result.embeddings[0]",
    "",
    "# Ara",
    "results = await faiss_search.search(query_embedding, top_k=3)",
    "",
    "print(f\"Query: '{query}'\\n\")",
    "print(f\"Sonuçlar ({results.query_time_ms:.2f}ms):\\n\")",
    "",
    "for i, result in enumerate(results.results, 1):",
    "    print(f\"{i}. {result.text}\")",
    "    print(f\"   Benzerlik: {result.score:.4f}\")",
    "    print(f\"   ID: {result.id}\")",
    "    print()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Farklı Query'ler"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "queries = [",
    "    \"programlama dilleri\",",
    "    \"web teknolojileri\",",
    "    \"veri analizi\",",
    "    \"konteyner ve orkestrasyon\"",
    "]",
    "",
    "for query in queries:",
    "    query_result = await embedder.embed(query)",
    "    results = await faiss_search.search(query_result.embeddings[0], top_k=2)",
    "    ",
    "    print(f\"Query: '{query}'\")",
    "    for i, result in enumerate(results.results, 1):",
    "        print(f\"  {i}. {result.text} (benzerlik: {result.score:.4f})\")",
    "    print()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing + Search Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Preprocessing ekle",
    "preprocessor = TurkishPreprocessor({",
    "    'lowercase': True,",
    "    'remove_punctuation': True,",
    "    'remove_stopwords': True,",
    "    'lemmatize': True",
    "})",
    "",
    "# Dökümanları işle",
    "raw_documents = [",
    "    \"Python PROGRAMLAMA dili çok güçlüdür!\",",
    "    \"Makine öğrenmesi, yapay zeka'nın alt dalıdır.\",",
    "    \"Doğal dil işleme metinleri analiz eder.\"",
    "]",
    "",
    "print(\"Orijinal dökümanlar:\")",
    "for i, doc in enumerate(raw_documents, 1):",
    "    print(f\"{i}. {doc}\")",
    "",
    "# Preprocessing",
    "preprocessed = await preprocessor.process(raw_documents)",
    "processed_docs = [p.text for p in preprocessed]",
    "",
    "print(\"\\nİşlenmiş dökümanlar:\")",
    "for i, doc in enumerate(processed_docs, 1):",
    "    print(f\"{i}. {doc}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Yeni index oluştur",
    "faiss_search2 = FAISSSearch({'dimension': dimension})",
    "",
    "# Embedding ve indeksleme",
    "embed_result2 = await embedder.embed(processed_docs)",
    "ids2 = [str(i) for i in range(len(processed_docs))]",
    "",
    "await faiss_search2.index(raw_documents, embed_result2.embeddings, ids2)",
    "",
    "# Arama",
    "query = \"yapay zeka makine öğrenmesi\"",
    "query_preprocessed = await preprocessor.process(query)",
    "query_embed = await embedder.embed(query_preprocessed.text)",
    "",
    "results = await faiss_search2.search(query_embed.embeddings[0], top_k=2)",
    "",
    "print(f\"Query: '{query}'\")",
    "print(f\"İşlenmiş query: '{query_preprocessed.text}'\\n\")",
    "for i, result in enumerate(results.results, 1):",
    "    print(f\"{i}. {result.text}\")",
    "    print(f\"   Benzerlik: {result.score:.4f}\\n\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Qdrant - Cloud Vektör Veritabanı",
    "",
    "Qdrant, yüksek performanslı bir vektör veritabanıdır."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Qdrant kontrolü",
    "qdrant_url = os.getenv('QDRANT_URL', 'http://localhost:6333')",
    "",
    "print(f\"Qdrant URL: {qdrant_url}\")",
    "print(\"\\nNot: Qdrant kullanmak için:\")",
    "print(\"  1. Docker ile: docker run -p 6333:6333 qdrant/qdrant\")",
    "print(\"  2. Cloud: https://cloud.qdrant.io/\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Qdrant search (opsiyonel)",
    "try:",
    "    qdrant_search = QdrantSearch({",
    "        'url': qdrant_url,",
    "        'collection': 'bns_nlp_demo'",
    "    })",
    "    ",
    "    # İndeksle",
    "    await qdrant_search.index(documents, embed_result.embeddings, ids, metadata)",
    "    ",
    "    # Ara",
    "    results = await qdrant_search.search(query_embedding, top_k=3)",
    "    ",
    "    print(\"✓ Qdrant arama başarılı\\n\")",
    "    for i, result in enumerate(results.results, 1):",
    "        print(f\"{i}. {result.text} (benzerlik: {result.score:.4f})\")",
    "except Exception as e:",
    "    print(f\"✗ Qdrant bağlantısı başarısız: {e}\")",
    "    print(\"  Qdrant sunucusunun çalıştığından emin olun\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performans Karşılaştırması"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Performans testi",
    "import matplotlib.pyplot as plt",
    "",
    "# Farklı döküman sayıları",
    "doc_counts = [10, 50, 100, 500, 1000]",
    "index_times = []",
    "search_times = []",
    "",
    "for count in doc_counts:",
    "    test_docs = [f\"Test döküman {i}\" for i in range(count)]",
    "    ",
    "    # Index time",
    "    start = time.time()",
    "    test_embeddings = await embedder.embed(test_docs)",
    "    test_search = FAISSSearch({'dimension': dimension})",
    "    test_ids = [str(i) for i in range(count)]",
    "    await test_search.index(test_docs, test_embeddings.embeddings, test_ids)",
    "    index_time = time.time() - start",
    "    index_times.append(index_time)",
    "    ",
    "    # Search time",
    "    start = time.time()",
    "    await test_search.search(query_embedding, top_k=10)",
    "    search_time = time.time() - start",
    "    search_times.append(search_time)",
    "    ",
    "    print(f\"{count:4d} döküman: index={index_time:.3f}s, search={search_time*1000:.2f}ms\")",
    "",
    "# Grafik",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))",
    "",
    "ax1.plot(doc_counts, index_times, marker='o', linewidth=2, markersize=8)",
    "ax1.set_xlabel('Döküman Sayısı', fontsize=12)",
    "ax1.set_ylabel('İndeksleme Süresi (s)', fontsize=12)",
    "ax1.set_title('İndeksleme Performansı', fontsize=14)",
    "ax1.grid(True, alpha=0.3)",
    "",
    "ax2.plot(doc_counts, [t*1000 for t in search_times], marker='o', linewidth=2, markersize=8, color='orange')",
    "ax2.set_xlabel('Döküman Sayısı', fontsize=12)",
    "ax2.set_ylabel('Arama Süresi (ms)', fontsize=12)",
    "ax2.set_title('Arama Performansı', fontsize=14)",
    "ax2.grid(True, alpha=0.3)",
    "",
    "plt.tight_layout()",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gerçek Dünya Örneği: Haber Arama Sistemi"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Örnek haber metinleri",
    "news_articles = [",
    "    \"Türkiye'de yapay zeka teknolojileri hızla gelişiyor. Yerli şirketler önemli projeler üretiyor.\",",
    "    \"Ekonomi alanında yeni düzenlemeler yapıldı. Merkez Bankası faiz kararını açıkladı.\",",
    "    \"Spor dünyasında heyecan verici gelişmeler yaşanıyor. Milli takım önemli bir galibiyet aldı.\",",
    "    \"Eğitim sisteminde dijital dönüşüm hızlanıyor. Uzaktan eğitim platformları yaygınlaşıyor.\",",
    "    \"Sağlık sektöründe teknoloji kullanımı artıyor. Yapay zeka destekli teşhis sistemleri geliştiriliyor.\",",
    "    \"İklim değişikliği ile mücadele kapsamında yeni projeler başlatıldı. Yenilenebilir enerji yatırımları artıyor.\",",
    "    \"Teknoloji şirketleri yeni ürünlerini tanıttı. Yapay zeka ve makine öğrenmesi ön planda.\",",
    "    \"Otomotiv sektöründe elektrikli araç üretimi hızlanıyor. Yerli otomobil projesi ilerliyor.\"",
    "]",
    "",
    "print(f\"{len(news_articles)} haber makalesi\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Haberleri işle ve indeksle",
    "preprocessed_news = await preprocessor.process(news_articles)",
    "processed_news = [p.text for p in preprocessed_news]",
    "",
    "news_embeddings = await embedder.embed(processed_news)",
    "",
    "news_search = FAISSSearch({'dimension': dimension})",
    "news_ids = [str(i) for i in range(len(news_articles))]",
    "news_metadata = [{'category': 'news', 'index': i} for i in range(len(news_articles))]",
    "",
    "await news_search.index(news_articles, news_embeddings.embeddings, news_ids, news_metadata)",
    "",
    "print(\"✓ Haberler indekslendi\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Farklı sorguları test et",
    "test_queries = [",
    "    \"yapay zeka teknolojileri\",",
    "    \"ekonomi ve finans\",",
    "    \"spor haberleri\",",
    "    \"eğitim ve teknoloji\",",
    "    \"sağlık sektörü\"",
    "]",
    "",
    "for query in test_queries:",
    "    # Query'yi işle",
    "    query_proc = await preprocessor.process(query)",
    "    query_emb = await embedder.embed(query_proc.text)",
    "    ",
    "    # Ara",
    "    results = await news_search.search(query_emb.embeddings[0], top_k=2)",
    "    ",
    "    print(f\"\\nQuery: '{query}'\")",
    "    print(\"-\" * 80)",
    "    for i, result in enumerate(results.results, 1):",
    "        print(f\"{i}. {result.text[:100]}...\")",
    "        print(f\"   Benzerlik: {result.score:.4f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonraki Adımlar",
    "",
    "- [Quickstart Notebook](quickstart.ipynb) - Hızlı başlangıç",
    "- [Preprocessing Notebook](preprocessing.ipynb) - Metin ön işleme",
    "- [Embeddings Notebook](embeddings.ipynb) - Embedding oluşturma",
    "- [API Dokümantasyonu](https://yourusername.github.io/bns-nlp-engine/api/search/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}