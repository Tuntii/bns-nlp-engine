{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metin Ön İşleme (Preprocessing)\n",
    "\n",
    "Bu notebook, bns-nlp-engine'in preprocessing özelliklerini detaylı olarak gösterir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from bnsnlp.preprocess import TurkishPreprocessor\n",
    "from bnsnlp.preprocess.normalizer import TurkishNormalizer\n",
    "from bnsnlp.preprocess.tokenizer import Tokenizer\n",
    "from bnsnlp.preprocess.stopwords import StopWords\n",
    "from bnsnlp.preprocess.lemmatizer import TurkishLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Temel Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basit örnek\n",
    "preprocessor = TurkishPreprocessor({\n",
    "    'lowercase': True,\n",
    "    'remove_punctuation': True,\n",
    "    'remove_stopwords': False,\n",
    "    'lemmatize': False\n",
    "})\n",
    "\n",
    "text = \"Merhaba DÜNYA! Bu bir TEST metnidir.\"\n",
    "result = await preprocessor.process(text)\n",
    "\n",
    "print(f\"Orijinal: {text}\")\n",
    "print(f\"İşlenmiş: {result.text}\")\n",
    "print(f\"Tokenlar: {result.tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Türkçe Karakter Normalizasyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = TurkishNormalizer()\n",
    "\n",
    "# Türkçe karakterler\n",
    "texts = [\n",
    "    \"İstanbul'da güzel bir gün\",\n",
    "    \"ÇAĞRI ŞEKER ÖĞRETMEN\",\n",
    "    \"ığüşöç karakterleri\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    normalized = normalizer.normalize(text)\n",
    "    print(f\"Orijinal:    {text}\")\n",
    "    print(f\"Normalize:   {normalized}\")\n",
    "    print(f\"Lowercase:   {normalized.lower()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "text = \"Merhaba dünya! Bu bir test metnidir. Python programlama dili.\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "print(f\"Metin: {text}\")\n",
    "print(f\"\\nTokenlar ({len(tokens)} adet):\")\n",
    "for i, token in enumerate(tokens, 1):\n",
    "    print(f\"  {i}. '{token}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stop Words Kaldırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = StopWords()\n",
    "\n",
    "text = \"Bu bir test metnidir ve çok önemli bilgiler içerir\"\n",
    "tokens = text.lower().split()\n",
    "\n",
    "print(f\"Orijinal tokenlar: {tokens}\")\n",
    "print(f\"\\nStop words: {[t for t in tokens if stopwords.is_stopword(t)]}\")\n",
    "\n",
    "filtered = stopwords.remove(tokens)\n",
    "print(f\"\\nFiltered tokenlar: {filtered}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = TurkishLemmatizer()\n",
    "\n",
    "words = [\n",
    "    \"kitaplar\",\n",
    "    \"evlerde\",\n",
    "    \"çalışıyorum\",\n",
    "    \"gidiyoruz\",\n",
    "    \"güzeldir\"\n",
    "]\n",
    "\n",
    "print(\"Lemmatization örnekleri:\\n\")\n",
    "for word in words:\n",
    "    lemma = lemmatizer.lemmatize(word)\n",
    "    print(f\"{word:15} -> {lemma}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Tam Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tüm özellikleri aktif et\n",
    "full_preprocessor = TurkishPreprocessor({\n",
    "    'lowercase': True,\n",
    "    'remove_punctuation': True,\n",
    "    'remove_stopwords': True,\n",
    "    'lemmatize': True\n",
    "})\n",
    "\n",
    "text = \"\"\"İstanbul'da yaşayan insanlar çok çalışkan ve başarılıdır. \n",
    "Onlar her gün işlerine gidiyorlar ve ailelerini mutlu ediyorlar.\"\"\"\n",
    "\n",
    "result = await full_preprocessor.process(text)\n",
    "\n",
    "print(f\"Orijinal metin:\")\n",
    "print(text)\n",
    "print(f\"\\nİşlenmiş metin:\")\n",
    "print(result.text)\n",
    "print(f\"\\nTokenlar ({len(result.tokens)} adet):\")\n",
    "print(result.tokens)\n",
    "print(f\"\\nMetadata:\")\n",
    "for key, value in result.metadata.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch İşleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Batch preprocessor\n",
    "batch_preprocessor = TurkishPreprocessor({\n",
    "    'lowercase': True,\n",
    "    'remove_punctuation': True,\n",
    "    'remove_stopwords': True,\n",
    "    'lemmatize': True,\n",
    "    'batch_size': 32\n",
    "})\n",
    "\n",
    "# Test metinleri\n",
    "texts = [\n",
    "    \"Python programlama dili çok güçlüdür\",\n",
    "    \"Makine öğrenmesi yapay zeka alt dalıdır\",\n",
    "    \"Doğal dil işleme metinleri analiz eder\",\n",
    "    \"Veri bilimi veriden içgörü çıkarır\",\n",
    "    \"Derin öğrenme sinir ağları kullanır\"\n",
    "] * 10  # 50 metin\n",
    "\n",
    "# Batch işleme\n",
    "start = time.time()\n",
    "results = await batch_preprocessor.process(texts)\n",
    "batch_time = time.time() - start\n",
    "\n",
    "print(f\"Batch işleme:\")\n",
    "print(f\"  Metin sayısı: {len(texts)}\")\n",
    "print(f\"  Süre: {batch_time:.3f}s\")\n",
    "print(f\"  Metin/saniye: {len(texts)/batch_time:.1f}\")\n",
    "\n",
    "# İlk 3 sonucu göster\n",
    "print(f\"\\nİlk 3 sonuç:\")\n",
    "for i, result in enumerate(results[:3], 1):\n",
    "    print(f\"\\n{i}. {result.text}\")\n",
    "    print(f\"   Tokenlar: {result.tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Karşılaştırma: Farklı Konfigürasyonlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"İstanbul'da yaşayan insanlar çok çalışkan ve başarılıdır.\"\n",
    "\n",
    "configs = [\n",
    "    {'name': 'Sadece lowercase', 'config': {'lowercase': True}},\n",
    "    {'name': 'Lowercase + punctuation', 'config': {'lowercase': True, 'remove_punctuation': True}},\n",
    "    {'name': 'Lowercase + stopwords', 'config': {'lowercase': True, 'remove_stopwords': True}},\n",
    "    {'name': 'Tam pipeline', 'config': {\n",
    "        'lowercase': True,\n",
    "        'remove_punctuation': True,\n",
    "        'remove_stopwords': True,\n",
    "        'lemmatize': True\n",
    "    }}\n",
    "]\n",
    "\n",
    "print(f\"Orijinal: {text}\\n\")\n",
    "\n",
    "for item in configs:\n",
    "    preprocessor = TurkishPreprocessor(item['config'])\n",
    "    result = await preprocessor.process(text)\n",
    "    \n",
    "    print(f\"{item['name']}:\")\n",
    "    print(f\"  {result.text}\")\n",
    "    print(f\"  Token sayısı: {len(result.tokens)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Gerçek Dünya Örneği: Haber Metni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_text = \"\"\"Türkiye'nin başkenti Ankara'da bugün önemli bir toplantı gerçekleştirildi. \n",
    "Toplantıya katılan yetkililer, ekonomik gelişmeler hakkında detaylı bilgiler paylaştılar. \n",
    "Yapılan açıklamalara göre, önümüzdeki dönemde birçok yeni proje hayata geçirilecek. \n",
    "Bu projeler, ülke ekonomisine önemli katkılar sağlayacak ve istihdam artışına yol açacak.\"\"\"\n",
    "\n",
    "preprocessor = TurkishPreprocessor({\n",
    "    'lowercase': True,\n",
    "    'remove_punctuation': True,\n",
    "    'remove_stopwords': True,\n",
    "    'lemmatize': True\n",
    "})\n",
    "\n",
    "result = await preprocessor.process(news_text)\n",
    "\n",
    "print(\"Haber Metni Analizi\\n\")\n",
    "print(f\"Orijinal uzunluk: {len(news_text)} karakter\")\n",
    "print(f\"İşlenmiş uzunluk: {len(result.text)} karakter\")\n",
    "print(f\"Token sayısı: {len(result.tokens)}\")\n",
    "print(f\"\\nAnahtar kelimeler (ilk 10):\")\n",
    "print(result.tokens[:10])\n",
    "print(f\"\\nİşlenmiş metin:\")\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Performans Analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Farklı batch size'lar ile test\n",
    "batch_sizes = [1, 8, 16, 32, 64]\n",
    "times = []\n",
    "\n",
    "test_texts = [\"Bu bir test metnidir\"] * 100\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    preprocessor = TurkishPreprocessor({\n",
    "        'lowercase': True,\n",
    "        'remove_punctuation': True,\n",
    "        'batch_size': batch_size\n",
    "    })\n",
    "    \n",
    "    start = time.time()\n",
    "    await preprocessor.process(test_texts)\n",
    "    elapsed = time.time() - start\n",
    "    times.append(elapsed)\n",
    "    \n",
    "    print(f\"Batch size {batch_size:2d}: {elapsed:.3f}s\")\n",
    "\n",
    "# Grafik\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(batch_sizes, times, marker='o')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.title('Preprocessing Performance vs Batch Size')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonraki Adımlar\n",
    "\n",
    "- [Embeddings Notebook](embeddings.ipynb) - Embedding oluşturma\n",
    "- [Search Notebook](search.ipynb) - Semantik arama\n",
    "- [API Dokümantasyonu](https://yourusername.github.io/bns-nlp-engine/api/preprocess/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
