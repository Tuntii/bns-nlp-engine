{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bns-nlp-engine Hızlı Başlangıç\n",
    "\n",
    "Bu notebook, bns-nlp-engine kütüphanesinin temel özelliklerini gösterir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kurulum\n",
    "\n",
    "```bash\n",
    "pip install bns-nlp-engine[all]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import'lar\n",
    "import asyncio\n",
    "from bnsnlp import Pipeline, Config\n",
    "from bnsnlp.core.registry import PluginRegistry\n",
    "from bnsnlp.preprocess import TurkishPreprocessor\n",
    "from bnsnlp.embed import OpenAIEmbedder, HuggingFaceEmbedder\n",
    "from bnsnlp.search import FAISSSearch\n",
    "from bnsnlp.classify import TurkishClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Metin Ön İşleme\n",
    "\n",
    "Türkçe metinleri normalize edin, tokenize edin ve temizleyin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessor oluştur\n",
    "preprocessor = TurkishPreprocessor({\n",
    "    'lowercase': True,\n",
    "    'remove_punctuation': True,\n",
    "    'remove_stopwords': True,\n",
    "    'lemmatize': True\n",
    "})\n",
    "\n",
    "# Tek metin işle\n",
    "text = \"Merhaba DÜNYA! Bu bir TEST metnidir.\"\n",
    "result = await preprocessor.process(text)\n",
    "\n",
    "print(f\"Orijinal: {text}\")\n",
    "print(f\"İşlenmiş: {result.text}\")\n",
    "print(f\"Tokenlar: {result.tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch işleme\n",
    "texts = [\n",
    "    \"Python programlama dili\",\n",
    "    \"Makine öğrenmesi algoritmaları\",\n",
    "    \"Doğal dil işleme teknikleri\"\n",
    "]\n",
    "\n",
    "results = await preprocessor.process(texts)\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\n{i+1}. Metin:\")\n",
    "    print(f\"   İşlenmiş: {result.text}\")\n",
    "    print(f\"   Token sayısı: {len(result.tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Embedding Oluşturma\n",
    "\n",
    "Metinleri vektörlere dönüştürün."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# API key'i environment variable'dan al\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key:\n",
    "    embedder = OpenAIEmbedder({\n",
    "        'api_key': api_key,\n",
    "        'model': 'text-embedding-3-small',\n",
    "        'batch_size': 16\n",
    "    })\n",
    "    \n",
    "    # Tek metin\n",
    "    result = await embedder.embed(\"Merhaba dünya\")\n",
    "    print(f\"Embedding boyutu: {result.dimensions}\")\n",
    "    print(f\"İlk 5 değer: {result.embeddings[0][:5]}\")\n",
    "    \n",
    "    # Batch\n",
    "    result = await embedder.embed(texts)\n",
    "    print(f\"\\nBatch: {len(result.embeddings)} embedding oluşturuldu\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY environment variable tanımlı değil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace Embeddings (Yerel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yerel model kullan (API key gerekmez)\n",
    "hf_embedder = HuggingFaceEmbedder({\n",
    "    'model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    'use_gpu': False  # CPU kullan\n",
    "})\n",
    "\n",
    "result = await hf_embedder.embed(\"Merhaba dünya\")\n",
    "print(f\"Embedding boyutu: {result.dimensions}\")\n",
    "print(f\"Model: {result.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Semantik Arama\n",
    "\n",
    "FAISS ile yerel semantik arama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS search oluştur\n",
    "search = FAISSSearch({'dimension': result.dimensions})\n",
    "\n",
    "# Dökümanları hazırla\n",
    "documents = [\n",
    "    \"Python programlama dili\",\n",
    "    \"Makine öğrenmesi algoritmaları\",\n",
    "    \"Doğal dil işleme teknikleri\",\n",
    "    \"Veri bilimi ve analitik\",\n",
    "    \"Derin öğrenme modelleri\"\n",
    "]\n",
    "\n",
    "# Embedding'leri oluştur\n",
    "doc_embeddings = await hf_embedder.embed(documents)\n",
    "\n",
    "# İndeksle\n",
    "ids = [str(i) for i in range(len(documents))]\n",
    "metadata = [{'category': 'tech', 'index': i} for i in range(len(documents))]\n",
    "\n",
    "await search.index(documents, doc_embeddings.embeddings, ids, metadata)\n",
    "\n",
    "print(f\"{len(documents)} döküman indekslendi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arama yap\n",
    "query = \"NLP teknikleri\"\n",
    "query_embedding = await hf_embedder.embed(query)\n",
    "\n",
    "results = await search.search(\n",
    "    query_embedding.embeddings[0],\n",
    "    top_k=3\n",
    ")\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"Sonuçlar ({results.query_time_ms:.2f}ms):\\n\")\n",
    "\n",
    "for i, result in enumerate(results.results, 1):\n",
    "    print(f\"{i}. {result.text}\")\n",
    "    print(f\"   Benzerlik: {result.score:.4f}\")\n",
    "    print(f\"   Metadata: {result.metadata}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pipeline Kullanımı\n",
    "\n",
    "Birden fazla adımı zincirleyin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registry ve config\n",
    "registry = PluginRegistry()\n",
    "registry.discover_plugins()\n",
    "config = Config()\n",
    "\n",
    "# Pipeline oluştur\n",
    "pipeline = Pipeline(config, registry)\n",
    "\n",
    "# Adımları ekle\n",
    "pipeline.add_step('preprocess', 'turkish', config={\n",
    "    'lowercase': True,\n",
    "    'remove_punctuation': True,\n",
    "    'lemmatize': True\n",
    "})\n",
    "\n",
    "# İşle\n",
    "text = \"Merhaba DÜNYA! Bu bir TEST metnidir.\"\n",
    "result = await pipeline.process(text)\n",
    "\n",
    "print(f\"Pipeline sonucu: {result.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tam Örnek: End-to-End\n",
    "\n",
    "Preprocessing, embedding ve search'ü birlikte kullanın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def full_example():\n",
    "    # 1. Dökümanları hazırla\n",
    "    documents = [\n",
    "        \"Python güçlü bir programlama dilidir\",\n",
    "        \"Makine öğrenmesi yapay zeka alt dalıdır\",\n",
    "        \"Doğal dil işleme metinleri analiz eder\",\n",
    "        \"Veri bilimi veriden içgörü çıkarır\",\n",
    "        \"Derin öğrenme sinir ağları kullanır\"\n",
    "    ]\n",
    "    \n",
    "    # 2. Preprocessing\n",
    "    preprocessor = TurkishPreprocessor({\n",
    "        'lowercase': True,\n",
    "        'remove_punctuation': True,\n",
    "        'remove_stopwords': True\n",
    "    })\n",
    "    \n",
    "    preprocessed = await preprocessor.process(documents)\n",
    "    processed_texts = [p.text for p in preprocessed]\n",
    "    \n",
    "    # 3. Embedding\n",
    "    embedder = HuggingFaceEmbedder({\n",
    "        'model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
    "        'use_gpu': False\n",
    "    })\n",
    "    \n",
    "    embeddings = await embedder.embed(processed_texts)\n",
    "    \n",
    "    # 4. İndeksleme\n",
    "    search = FAISSSearch({'dimension': embeddings.dimensions})\n",
    "    ids = [str(i) for i in range(len(documents))]\n",
    "    \n",
    "    await search.index(\n",
    "        documents,  # Orijinal metinleri sakla\n",
    "        embeddings.embeddings,\n",
    "        ids\n",
    "    )\n",
    "    \n",
    "    # 5. Arama\n",
    "    query = \"yapay zeka ve makine öğrenmesi\"\n",
    "    \n",
    "    # Query'yi işle\n",
    "    query_preprocessed = await preprocessor.process(query)\n",
    "    query_embedding = await embedder.embed(query_preprocessed.text)\n",
    "    \n",
    "    # Ara\n",
    "    results = await search.search(\n",
    "        query_embedding.embeddings[0],\n",
    "        top_k=3\n",
    "    )\n",
    "    \n",
    "    # Sonuçları göster\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    print(\"En benzer dökümanlar:\\n\")\n",
    "    \n",
    "    for i, result in enumerate(results.results, 1):\n",
    "        print(f\"{i}. {result.text}\")\n",
    "        print(f\"   Benzerlik: {result.score:.4f}\\n\")\n",
    "\n",
    "# Çalıştır\n",
    "await full_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonraki Adımlar\n",
    "\n",
    "- [Preprocessing Notebook](preprocessing.ipynb) - Detaylı preprocessing örnekleri\n",
    "- [Embeddings Notebook](embeddings.ipynb) - Farklı embedding provider'ları\n",
    "- [Search Notebook](search.ipynb) - İleri seviye arama teknikleri\n",
    "- [Dokümantasyon](https://yourusername.github.io/bns-nlp-engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
