{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings (Vektör Temsilleri)\n",
    "\n",
    "Bu notebook, bns-nlp-engine'in farklı embedding provider'larını kullanarak metin vektörleştirme özelliklerini gösterir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from bnsnlp.embed import OpenAIEmbedder, CohereEmbedder, HuggingFaceEmbedder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. OpenAI Embeddings\n",
    "\n",
    "OpenAI'ın text-embedding modelleri ile vektör oluşturma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API key kontrolü\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_key:\n",
    "    print(\"✓ OpenAI API key bulundu\")\n",
    "else:\n",
    "    print(\"✗ OPENAI_API_KEY environment variable tanımlı değil\")\n",
    "    print(\"  export OPENAI_API_KEY='your-key-here'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if openai_key:\n",
    "    # OpenAI embedder oluştur\n",
    "    openai_embedder = OpenAIEmbedder({\n",
    "        'api_key': openai_key,\n",
    "        'model': 'text-embedding-3-small',\n",
    "        'batch_size': 16\n",
    "    })\n",
    "    \n",
    "    # Tek metin\n",
    "    text = \"Merhaba dünya, bu bir test metnidir.\"\n",
    "    result = await openai_embedder.embed(text)\n",
    "    \n",
    "    print(f\"Model: {result.model}\")\n",
    "    print(f\"Embedding boyutu: {result.dimensions}\")\n",
    "    print(f\"İlk 10 değer: {result.embeddings[0][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if openai_key:\n",
    "    # Batch işleme\n",
    "    texts = [\n",
    "        \"Python programlama dili\",\n",
    "        \"Makine öğrenmesi algoritmaları\",\n",
    "        \"Doğal dil işleme teknikleri\",\n",
    "        \"Veri bilimi ve analitik\",\n",
    "        \"Derin öğrenme modelleri\"\n",
    "    ]\n",
    "    \n",
    "    start = time.time()\n",
    "    result = await openai_embedder.embed(texts)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"Batch işleme:\")\n",
    "    print(f\"  Metin sayısı: {len(texts)}\")\n",
    "    print(f\"  Embedding sayısı: {len(result.embeddings)}\")\n",
    "    print(f\"  Süre: {elapsed:.3f}s\")\n",
    "    print(f\"  Metin/saniye: {len(texts)/elapsed:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cohere Embeddings\n",
    "\n",
    "Cohere'in multilingual embedding modelleri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API key kontrolü\n",
    "cohere_key = os.getenv('COHERE_API_KEY')\n",
    "\n",
    "if cohere_key:\n",
    "    print(\"✓ Cohere API key bulundu\")\n",
    "else:\n",
    "    print(\"✗ COHERE_API_KEY environment variable tanımlı değil\")\n",
    "    print(\"  export COHERE_API_KEY='your-key-here'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cohere_key:\n",
    "    # Cohere embedder oluştur\n",
    "    cohere_embedder = CohereEmbedder({\n",
    "        'api_key': cohere_key,\n",
    "        'model': 'embed-multilingual-v3.0',\n",
    "        'batch_size': 96\n",
    "    })\n",
    "    \n",
    "    # Tek metin\n",
    "    text = \"Türkçe doğal dil işleme\"\n",
    "    result = await cohere_embedder.embed(text)\n",
    "    \n",
    "    print(f\"Model: {result.model}\")\n",
    "    print(f\"Embedding boyutu: {result.dimensions}\")\n",
    "    print(f\"İlk 10 değer: {result.embeddings[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. HuggingFace Embeddings (Yerel)\n",
    "\n",
    "Yerel olarak çalışan sentence-transformers modelleri. API key gerektirmez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace embedder oluştur\n",
    "hf_embedder = HuggingFaceEmbedder({\n",
    "    'model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    'use_gpu': False  # CPU kullan\n",
    "})\n",
    "\n",
    "# Tek metin\n",
    "text = \"Merhaba dünya, bu bir test metnidir.\"\n",
    "result = await hf_embedder.embed(text)\n",
    "\n",
    "print(f\"Model: {result.model}\")\n",
    "print(f\"Embedding boyutu: {result.dimensions}\")\n",
    "print(f\"İlk 10 değer: {result.embeddings[0][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch işleme\n",
    "texts = [\n",
    "    \"Python programlama dili\",\n",
    "    \"Makine öğrenmesi algoritmaları\",\n",
    "    \"Doğal dil işleme teknikleri\",\n",
    "    \"Veri bilimi ve analitik\",\n",
    "    \"Derin öğrenme modelleri\"\n",
    "]\n",
    "\n",
    "start = time.time()\n",
    "result = await hf_embedder.embed(texts)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Batch işleme:\")\n",
    "print(f\"  Metin sayısı: {len(texts)}\")\n",
    "print(f\"  Embedding sayısı: {len(result.embeddings)}\")\n",
    "print(f\"  Süre: {elapsed:.3f}s\")\n",
    "print(f\"  Metin/saniye: {len(texts)/elapsed:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GPU Desteği\n",
    "\n",
    "HuggingFace modelleri GPU ile hızlandırılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# GPU kontrolü\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✓ GPU bulundu: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  CUDA version: {torch.version.cuda}\")\n",
    "    use_gpu = True\n",
    "else:\n",
    "    print(\"✗ GPU bulunamadı, CPU kullanılacak\")\n",
    "    use_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU ile embedder\n",
    "if use_gpu:\n",
    "    hf_gpu_embedder = HuggingFaceEmbedder({\n",
    "        'model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
    "        'use_gpu': True\n",
    "    })\n",
    "    \n",
    "    # Test metinleri\n",
    "    test_texts = [\"Bu bir test metnidir\"] * 100\n",
    "    \n",
    "    # CPU\n",
    "    hf_cpu = HuggingFaceEmbedder({'model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2', 'use_gpu': False})\n",
    "    start = time.time()\n",
    "    await hf_cpu.embed(test_texts)\n",
    "    cpu_time = time.time() - start\n",
    "    \n",
    "    # GPU\n",
    "    start = time.time()\n",
    "    await hf_gpu_embedder.embed(test_texts)\n",
    "    gpu_time = time.time() - start\n",
    "    \n",
    "    print(f\"100 metin için:\")\n",
    "    print(f\"  CPU: {cpu_time:.3f}s\")\n",
    "    print(f\"  GPU: {gpu_time:.3f}s\")\n",
    "    print(f\"  Hızlanma: {cpu_time/gpu_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Embedding Karşılaştırması\n",
    "\n",
    "Farklı provider'ların embedding'lerini karşılaştırma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Test metinleri\n",
    "text1 = \"Python programlama dili\"\n",
    "text2 = \"Python kodlama\"\n",
    "text3 = \"Makine öğrenmesi\"\n",
    "\n",
    "# HuggingFace ile embedding'ler\n",
    "result = await hf_embedder.embed([text1, text2, text3])\n",
    "embeddings = np.array(result.embeddings)\n",
    "\n",
    "# Benzerlik matrisi\n",
    "similarity = cosine_similarity(embeddings)\n",
    "\n",
    "print(\"Cosine Similarity Matrisi:\\n\")\n",
    "print(f\"{'':25} {text1:25} {text2:25} {text3:25}\")\n",
    "print(\"-\" * 105)\n",
    "for i, text in enumerate([text1, text2, text3]):\n",
    "    print(f\"{text:25}\", end=\"\")\n",
    "    for j in range(3):\n",
    "        print(f\" {similarity[i][j]:24.4f}\", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Farklı Modeller Karşılaştırması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Farklı HuggingFace modelleri\n",
    "models = [\n",
    "    'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
    "    'sentence-transformers/distiluse-base-multilingual-cased-v2'\n",
    "]\n",
    "\n",
    "test_text = \"Türkçe doğal dil işleme\"\n",
    "\n",
    "print(f\"Test metni: {test_text}\\n\")\n",
    "print(f\"{'Model':<60} {'Boyut':<10} {'Süre (ms)'}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "for model_name in models:\n",
    "    embedder = HuggingFaceEmbedder({\n",
    "        'model': model_name,\n",
    "        'use_gpu': False\n",
    "    })\n",
    "    \n",
    "    start = time.time()\n",
    "    result = await embedder.embed(test_text)\n",
    "    elapsed = (time.time() - start) * 1000\n",
    "    \n",
    "    model_short = model_name.split('/')[-1]\n",
    "    print(f\"{model_short:<60} {result.dimensions:<10} {elapsed:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Preprocessing + Embedding Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bnsnlp.preprocess import TurkishPreprocessor\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = TurkishPreprocessor({\n",
    "    'lowercase': True,\n",
    "    'remove_punctuation': True,\n",
    "    'remove_stopwords': True,\n",
    "    'lemmatize': True\n",
    "})\n",
    "\n",
    "# Orijinal metinler\n",
    "raw_texts = [\n",
    "    \"Python PROGRAMLAMA dili çok güçlüdür!\",\n",
    "    \"Makine öğrenmesi yapay zeka'nın alt dalıdır.\",\n",
    "    \"Doğal dil işleme, metinleri analiz eder.\"\n",
    "]\n",
    "\n",
    "print(\"Orijinal metinler:\")\n",
    "for i, text in enumerate(raw_texts, 1):\n",
    "    print(f\"{i}. {text}\")\n",
    "\n",
    "# Preprocessing\n",
    "preprocessed = await preprocessor.process(raw_texts)\n",
    "processed_texts = [p.text for p in preprocessed]\n",
    "\n",
    "print(\"\\nİşlenmiş metinler:\")\n",
    "for i, text in enumerate(processed_texts, 1):\n",
    "    print(f\"{i}. {text}\")\n",
    "\n",
    "# Embedding\n",
    "result = await hf_embedder.embed(processed_texts)\n",
    "\n",
    "print(f\"\\nEmbedding'ler oluşturuldu:\")\n",
    "print(f\"  Sayı: {len(result.embeddings)}\")\n",
    "print(f\"  Boyut: {result.dimensions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performans Analizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Farklı batch size'lar\n",
    "batch_sizes = [1, 4, 8, 16, 32, 64]\n",
    "test_texts = [\"Bu bir test metnidir\"] * 100\n",
    "\n",
    "times = []\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    embedder = HuggingFaceEmbedder({\n",
    "        'model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
    "        'use_gpu': False\n",
    "    })\n",
    "    \n",
    "    start = time.time()\n",
    "    # Batch'lere böl ve işle\n",
    "    for i in range(0, len(test_texts), batch_size):\n",
    "        batch = test_texts[i:i+batch_size]\n",
    "        await embedder.embed(batch)\n",
    "    elapsed = time.time() - start\n",
    "    times.append(elapsed)\n",
    "    \n",
    "    print(f\"Batch size {batch_size:2d}: {elapsed:.3f}s ({len(test_texts)/elapsed:.1f} text/s)\")\n",
    "\n",
    "# Grafik\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(batch_sizes, times, marker='o', linewidth=2, markersize=8)\n",
    "plt.xlabel('Batch Size', fontsize=12)\n",
    "plt.ylabel('Time (seconds)', fontsize=12)\n",
    "plt.title('Embedding Performance vs Batch Size (100 texts)', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Embedding Kalitesi Testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benzer ve farklı metinler\n",
    "test_cases = [\n",
    "    (\"Python programlama\", \"Python kodlama\", \"Benzer\"),\n",
    "    (\"Makine öğrenmesi\", \"Yapay zeka\", \"İlgili\"),\n",
    "    (\"Doğal dil işleme\", \"Metin analizi\", \"İlgili\"),\n",
    "    (\"Python programlama\", \"Futbol maçı\", \"Farklı\"),\n",
    "    (\"Makine öğrenmesi\", \"Yemek tarifi\", \"Farklı\")\n",
    "]\n",
    "\n",
    "print(f\"{'Metin 1':<25} {'Metin 2':<25} {'Beklenen':<15} {'Benzerlik'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for text1, text2, expected in test_cases:\n",
    "    result = await hf_embedder.embed([text1, text2])\n",
    "    embeddings = np.array(result.embeddings)\n",
    "    similarity = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "    \n",
    "    print(f\"{text1:<25} {text2:<25} {expected:<15} {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Gerçek Dünya Örneği: Döküman Benzerliği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Örnek dökümanlar\n",
    "documents = [\n",
    "    \"Python, yüksek seviyeli bir programlama dilidir. Okunabilir sözdizimi ve güçlü kütüphaneleri ile popülerdir.\",\n",
    "    \"Makine öğrenmesi, bilgisayarların veriden öğrenmesini sağlayan yapay zeka dalıdır. Tahmin ve sınıflandırma yapar.\",\n",
    "    \"Doğal dil işleme, bilgisayarların insan dilini anlamasını sağlar. Metin analizi ve dil modelleri kullanır.\",\n",
    "    \"Veri bilimi, veriden anlamlı bilgiler çıkarma sürecidir. İstatistik, programlama ve alan bilgisi gerektirir.\",\n",
    "    \"Derin öğrenme, yapay sinir ağları kullanan makine öğrenmesi yöntemidir. Görüntü ve ses işlemede başarılıdır.\"\n",
    "]\n",
    "\n",
    "# Preprocessing\n",
    "preprocessed = await preprocessor.process(documents)\n",
    "processed_docs = [p.text for p in preprocessed]\n",
    "\n",
    "# Embedding\n",
    "result = await hf_embedder.embed(processed_docs)\n",
    "embeddings = np.array(result.embeddings)\n",
    "\n",
    "# Benzerlik matrisi\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# Görselleştirme\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(similarity_matrix, cmap='YlOrRd', aspect='auto')\n",
    "plt.colorbar(label='Cosine Similarity')\n",
    "plt.title('Döküman Benzerlik Matrisi', fontsize=14, pad=20)\n",
    "\n",
    "labels = ['Python', 'ML', 'NLP', 'Data Sci', 'Deep Learn']\n",
    "plt.xticks(range(len(labels)), labels, rotation=45, ha='right')\n",
    "plt.yticks(range(len(labels)), labels)\n",
    "\n",
    "# Değerleri göster\n",
    "for i in range(len(labels)):\n",
    "    for j in range(len(labels)):\n",
    "        text = plt.text(j, i, f'{similarity_matrix[i, j]:.2f}',\n",
    "                       ha=\"center\", va=\"center\", color=\"black\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# En benzer döküman çiftleri\n",
    "print(\"\\nEn benzer döküman çiftleri:\\n\")\n",
    "pairs = []\n",
    "for i in range(len(documents)):\n",
    "    for j in range(i+1, len(documents)):\n",
    "        pairs.append((i, j, similarity_matrix[i][j]))\n",
    "\n",
    "pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "for i, j, sim in pairs[:3]:\n",
    "    print(f\"Benzerlik: {sim:.4f}\")\n",
    "    print(f\"  Döküman {i+1}: {documents[i][:60]}...\")\n",
    "    print(f\"  Döküman {j+1}: {documents[j][:60]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonraki Adımlar\n",
    "\n",
    "- [Search Notebook](search.ipynb) - Embedding'leri kullanarak semantik arama\n",
    "- [Quickstart Notebook](quickstart.ipynb) - Hızlı başlangıç\n",
    "- [API Dokümantasyonu](https://yourusername.github.io/bns-nlp-engine/api/embed/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
